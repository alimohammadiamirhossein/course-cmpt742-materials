{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CMPT 742 - Fall 2025\n",
        "# Image Classification with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0saV9BzOSVp",
        "outputId": "9bc8a7ae-a849-4589-9009-eddb54c64c01"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision tensorboard torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAF-FZKQZUtK"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv054njYZTcS"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcqrCDAZX5z"
      },
      "source": [
        "Load CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb3PV0WBZZj8",
        "outputId": "9a93a597-bf2b-48a5-8403-ee5b626eb2d5"
      },
      "outputs": [],
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762))  # CIFAR-100 normalization values\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "batch_size = ...\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = ...\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = ...\n",
        "\n",
        "# Define a function to visualize some samples from the dataset\n",
        "def imshow(img):\n",
        "    ...\n",
        "\n",
        "# Show some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "imshow(torchvision.utils.make_grid(images[:8]))  # Show 8 images in a grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW2gzdPHZkoX"
      },
      "source": [
        "Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0buf69gZeev"
      },
      "outputs": [],
      "source": [
        "# Load the pre-defined ResNet18 model and adjust it for CIFAR-100\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# Define the model\n",
        "model = resnet18()  # Set num_classes to 100 for CIFAR-100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ... # set the model on cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkemH3SfbbrS"
      },
      "outputs": [],
      "source": [
        "def count_parameters_in_millions(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total_params / 1_000_000  # Divide by 1 million to convert to millions\n",
        "\n",
        "# Example usage:\n",
        "total_params_in_millions = count_parameters_in_millions(model)\n",
        "print(f'Total trainable parameters: {total_params_in_millions:.2f} million')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbwyAV_YPTKs"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvQvxBTkZ0qQ"
      },
      "source": [
        "Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtL4G_tcZ0YW",
        "outputId": "5877a53b-9df2-427a-8a32-900f1a5f86c3"
      },
      "outputs": [],
      "source": [
        "# prompt: print model parameters\n",
        "print(\"Model Parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "  print(f\"Name: {name}, Shape: {param.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNlDJScEx7fW"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg-oaEWpZm7P"
      },
      "source": [
        "Define Loss Function, Optimizer, and TensorBoard Writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1YZOnxqZncv"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = ...\n",
        "# optimizer = optim.Adam(model.fc.parameters(), lr=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter('runs/cifar100_resnet18')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn_cSC--QXul"
      },
      "outputs": [],
      "source": [
        "# Function to save a checkpoint in the TensorBoard log directory\n",
        "def save_checkpoint(model, optimizer, epoch, loss_metric, accuracy_metric, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\"\n",
        "\n",
        "    # Use .compute() to get the values of the metrics\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss_metric.compute(),  # Get the computed loss\n",
        "        'accuracy': accuracy_metric.compute()  # Get the computed accuracy\n",
        "    }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f'Checkpoint saved at {checkpoint_path}')\n",
        "\n",
        "# Function to load a checkpoint from the TensorBoard log directory\n",
        "def load_checkpoint(model, optimizer, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    import glob\n",
        "    # Find the latest checkpoint (e.g., based on the highest epoch number)\n",
        "    checkpoint_paths = glob.glob(f\"{checkpoint_dir}/checkpoint_epoch_*.pth\")\n",
        "    checkpoint_paths.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "    latest_checkpoint = checkpoint_paths[-1]\n",
        "\n",
        "    checkpoint = torch.load(latest_checkpoint)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "    loss = checkpoint['loss']\n",
        "    accuracy = checkpoint['accuracy']\n",
        "    print(f'Checkpoint loaded from {latest_checkpoint}. Resuming training from epoch {start_epoch}')\n",
        "\n",
        "    return start_epoch, loss, accuracy  # You can return these for reference but don't update accuracy_metric with them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0kyX-UtQkf-"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Updated training function with torchmetrics and resuming capability\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=1, start_epoch=0, resume=False, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    # Initialize the metrics\n",
        "    loss_metric = torchmetrics.MeanMetric()\n",
        "    accuracy_metric = torchmetrics.Accuracy('multiclass', num_classes=100)\n",
        "\n",
        "    # Load checkpoint if resuming\n",
        "    if resume:\n",
        "        ...\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2xbMQhnQ_SK"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, criterion, optimizer, checkpoint_dir='runs/cifar100_resnet18'):\n",
        "    # Load the model from the latest checkpoint if needed\n",
        "    load_checkpoint(model, optimizer, checkpoint_dir)\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training from scratch\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10, resume=False, checkpoint_dir='runs/cifar100_resnet18')\n",
        "\n",
        "# If training gets interrupted, resume from the last checkpoint:\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10, resume=True, checkpoint_dir='runs/cifar100_resnet18')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Start TensorBoard and point it to the log directory used by SummaryWriter\n",
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkw5zXwxRPy6"
      },
      "outputs": [],
      "source": [
        "def visualize_feature_maps(model, layer_name, image):\n",
        "    # Get the specified layer's output\n",
        "    activation = {}\n",
        "    def hook_fn(module, input, output):\n",
        "        activation[layer_name] = output\n",
        "\n",
        "    layer = dict(model.named_modules())[layer_name]\n",
        "    layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    # Pass the image through the model\n",
        "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "    model(image)\n",
        "\n",
        "    # Extract and plot the feature maps\n",
        "    feature_maps = activation[layer_name].squeeze().cpu().detach()\n",
        "    fig, axes = plt.subplots(1, min(8, feature_maps.size(0)), figsize=(15, 15))\n",
        "    for i in range(min(8, feature_maps.size(0))):\n",
        "        axes[i].imshow(feature_maps[i], cmap='viridis')\n",
        "        axes[i].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataiter = iter(test_dataset)\n",
        "image = next(dataiter)[0]\n",
        "imshow(image)\n",
        "visualize_feature_maps(model, \"conv1\", image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWjwU_hoRSSK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def visualize_tsne(model, loader):\n",
        "    features = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            features.extend(output.cpu().numpy())\n",
        "            labels.extend(targets.numpy())\n",
        "\n",
        "    # Convert the list of features into a numpy array\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Perform t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(features)\n",
        "\n",
        "    # Create a DataFrame for visualization\n",
        "    df = pd.DataFrame({'x': tsne_results[:, 0], 'y': tsne_results[:, 1], 'label': labels})\n",
        "\n",
        "    # Plot the t-SNE results using seaborn\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(x='x', y='y', hue='label', palette='tab10', data=df, legend='full', alpha=0.7)\n",
        "    plt.title('t-SNE of MobileNetV2 Features')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_tsne(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E74VjTJXRZOS"
      },
      "outputs": [],
      "source": [
        "def get_incorrect_predictions(model, loader, max_samples=10):\n",
        "    model.eval()\n",
        "    incorrect_samples = []\n",
        "    incorrect_labels = []\n",
        "    incorrect_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            # TODO complete this function\n",
        "            ...\n",
        "\n",
        "    return incorrect_samples, incorrect_labels, incorrect_preds\n",
        "\n",
        "\n",
        "def visualize_incorrect_predictions(model, loader, class_names, max_samples=10):\n",
        "    incorrect_samples, incorrect_labels, incorrect_preds = get_incorrect_predictions(model, loader, max_samples=max_samples)\n",
        "\n",
        "    # Plot the images with true and predicted labels\n",
        "    fig, axes = plt.subplots(1, len(incorrect_samples), figsize=(15, 5))\n",
        "    if len(incorrect_samples) == 1:\n",
        "        axes = [axes]  # To handle the case where there's only one incorrect sample\n",
        "\n",
        "    for idx, (img, true_label, pred_label) in enumerate(zip(incorrect_samples, incorrect_labels, incorrect_preds)):\n",
        "        img = img.permute(1, 2, 0)  # Convert from (C, H, W) to (H, W, C)\n",
        "        img = img * 0.2673 + 0.5071  # Unnormalize for CIFAR100: (std_dev * image + mean)\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]}', fontsize=10)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_incorrect_predictions(model, test_loader, train_dataset.classes, max_samples=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
